{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK #1: UNDERSTAND THE PROBLEM STATEMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Our goal is to build a multiclassifier model based on deep learning to classify various traffic signs. \n",
    "- Dataset that we are using to train the model is **German Traffic Sign Recognition Benchmark**.\n",
    "- Dataset consists of 43 classes: \n",
    "- ( 0, b'Speed limit (20km/h)') ( 1, b'Speed limit (30km/h)') ( 2, b'Speed limit (50km/h)') ( 3, b'Speed limit (60km/h)') ( 4, b'Speed limit (70km/h)') \n",
    "- ( 5, b'Speed limit (80km/h)') ( 6, b'End of speed limit (80km/h)') ( 7, b'Speed limit (100km/h)') ( 8, b'Speed limit (120km/h)') ( 9, b'No passing') \n",
    "- (10, b'No passing for vehicles over 3.5 metric tons') (11, b'Right-of-way at the next intersection') (12, b'Priority road') (13, b'Yield') (14, b'Stop') \n",
    "- (15, b'No vehicles') (16, b'Vehicles over 3.5 metric tons prohibited') (17, b'No entry')\n",
    "- (18, b'General caution') (19, b'Dangerous curve to the left')\n",
    "- (20, b'Dangerous curve to the right') (21, b'Double curve')\n",
    "- (22, b'Bumpy road') (23, b'Slippery road')\n",
    "- (24, b'Road narrows on the right') (25, b'Road work')\n",
    "- (26, b'Traffic signals') (27, b'Pedestrians') (28, b'Children crossing')\n",
    "- (29, b'Bicycles crossing') (30, b'Beware of ice/snow')\n",
    "- (31, b'Wild animals crossing')\n",
    "- (32, b'End of all speed and passing limits') (33, b'Turn right ahead')\n",
    "- (34, b'Turn left ahead') (35, b'Ahead only') (36, b'Go straight or right')\n",
    "- (37, b'Go straight or left') (38, b'Keep right') (39, b'Keep left')\n",
    "- (40, b'Roundabout mandatory') (41, b'End of no passing')\n",
    "- (42, b'End of no passing by vehicles over 3.5 metric tons')\n",
    "\n",
    "\n",
    "\n",
    "- **Data Source** - https://www.kaggle.com/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK #2: GET THE DATA AND VISUALIZE IT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"train.p\", mode='rb') as training_data:\n",
    "    train = pickle.load(training_data)\n",
    "with open(\"valid.p\", mode='rb') as validation_data:\n",
    "    valid = pickle.load(validation_data)\n",
    "with open(\"test.p\", mode='rb') as testing_data:\n",
    "    test = pickle.load(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train['features'], train['labels']\n",
    "X_validation, y_validation = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "i = np.random.randint(1, len(X_test))\n",
    "plt.imshow(X_test[i])\n",
    "print('label = ', y_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MINI CHALLENGE\n",
    "- Complete the code below to print out 5 by 5 grid showing random traffic sign images along with their corresponding labels as their titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's view more images in a grid format\n",
    "# Define the dimensions of the plot grid \n",
    "W_grid = 5\n",
    "L_grid = 5\n",
    "\n",
    "# fig, axes = plt.subplots(L_grid, W_grid)\n",
    "# subplot return the figure object and axes object\n",
    "# we can use the axes object to plot specific figures at various locations\n",
    "\n",
    "fig, axes = plt.subplots(L_grid, W_grid, figsize = (10,10))\n",
    "\n",
    "axes = axes.ravel() # flaten the 15 x 15 matrix into 225 array\n",
    "\n",
    "n_training = len(X_test) # get the length of the training dataset\n",
    "\n",
    "# Select a random number from 0 to n_training\n",
    "for i in np.arange(0, W_grid * L_grid): # create evenly spaces variables \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK #3: IMPORT SAGEMAKER/BOTO3, CREATE A SESSION, DEFINE S3 AND ROLE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boto3 is the Amazon Web Services (AWS) Software Development Kit (SDK) for Python\n",
    "# Boto3 allows Python developer to write software that makes use of services like Amazon S3 and Amazon EC2\n",
    "\n",
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "# Let's create a Sagemaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Let's define the S3 bucket and prefix that we want to use in this session\n",
    "bucket = 'sagemaker-practical' # bucket named 'sagemaker-practical' was created beforehand\n",
    "prefix = 'traffic-sign-classifier' # prefix is the subfolder within the bucket.\n",
    "\n",
    "# Let's get the execution role for the notebook instance. \n",
    "# This is the IAM role that you created when you created your notebook instance. You pass the role to the training job.\n",
    "# Note that AWS Identity and Access Management (IAM) role that Amazon SageMaker can assume to perform tasks on your behalf (for example, reading training results, called model artifacts, from the S3 bucket and writing training results to Amazon S3). \n",
    "role = sagemaker.get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK #4: UPLOAD THE DATA TO S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory to store the training and validation data\n",
    "\n",
    "import os\n",
    "os.makedirs(\"./data\", exist_ok = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save several arrays into a single file in uncompressed .npz format\n",
    "# Read more here: https://numpy.org/devdocs/reference/generated/numpy.savez.html\n",
    "\n",
    "np.savez('./data/training', image = X_train, label = y_train)\n",
    "np.savez('./data/validation', image = X_test, label = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the training and validation data to S3 bucket\n",
    "\n",
    "prefix = 'traffic-sign'\n",
    "\n",
    "training_input_path   = sagemaker_session.upload_data('data/training.npz', key_prefix = prefix + '/training')\n",
    "validation_input_path = sagemaker_session.upload_data('data/validation.npz', key_prefix = prefix + '/validation')\n",
    "\n",
    "print(training_input_path)\n",
    "print(validation_input_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK #5: TRAIN THE CNN LENET MODEL USING SAGEMAKER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model consists of the following layers: \n",
    "\n",
    "- STEP 1: THE FIRST CONVOLUTIONAL LAYER #1\n",
    "\n",
    "\n",
    "    - Input = 32x32x3\n",
    "    - Output = 28x28x6\n",
    "    - Output = (Input-filter+1)/Stride* => (32-5+1)/1=28\n",
    "    - Used a 5x5 Filter with input depth of 3 and output depth of 6\n",
    "    - Apply a RELU Activation function to the output\n",
    "    - pooling for input, Input = 28x28x6 and Output = 14x14x6\n",
    "\n",
    "\n",
    "    * Stride is the amount by which the kernel is shifted when the kernel is passed over the image.\n",
    "\n",
    "- STEP 2: THE SECOND CONVOLUTIONAL LAYER #2\n",
    "\n",
    "\n",
    "    - Input = 14x14x6\n",
    "    - Output = 10x10x16\n",
    "    - Layer 2: Convolutional layer with Output = 10x10x16\n",
    "    - Output = (Input-filter+1)/strides => 10 = 14-5+1/1\n",
    "    - Apply a RELU Activation function to the output\n",
    "    - Pooling with Input = 10x10x16 and Output = 5x5x16\n",
    "\n",
    "- STEP 3: FLATTENING THE NETWORK\n",
    "\n",
    "\n",
    "    - Flatten the network with Input = 5x5x16 and Output = 400\n",
    "\n",
    "- STEP 4: FULLY CONNECTED LAYER\n",
    "\n",
    "\n",
    "    - Layer 3: Fully Connected layer with Input = 400 and Output = 120\n",
    "    - Apply a RELU Activation function to the output\n",
    "\n",
    "- STEP 5: ANOTHER FULLY CONNECTED LAYER\n",
    "\n",
    "\n",
    "    - Layer 4: Fully Connected Layer with Input = 120 and Output = 84\n",
    "    - Apply a RELU Activation function to the output\n",
    "\n",
    "- STEP 6: FULLY CONNECTED LAYER\n",
    "\n",
    "\n",
    "    - Layer 5: Fully Connected layer with Input = 84 and Output = 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize train-cnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "# To Train a TensorFlow model, we will use TensorFlow estimator from the Sagemaker SDK\n",
    "\n",
    "# entry_point: a script that will run in a container. This script will include model description and training. \n",
    "# role: a role that's obtained The role assigned to the running notebook. \n",
    "# train_instance_count: number of container instances used to train the model.\n",
    "# train_instance_type: instance type!\n",
    "# framwork_version: version of Tensorflow\n",
    "# py_version: Python version.\n",
    "# script_mode: allows for running script in the container. \n",
    "# hyperparameters: indicate the hyperparameters for the training job such as epochs and learning rate\n",
    "\n",
    "\n",
    "tf_estimator = TensorFlow(entry_point='train-cnn.py', \n",
    "                          role=role,\n",
    "                          train_instance_count=1, \n",
    "                          train_instance_type='ml.c4.2xlarge',\n",
    "                          framework_version='1.12', \n",
    "                          py_version='py3',\n",
    "                          script_mode=True,\n",
    "                          hyperparameters={\n",
    "                              'epochs': 2 ,\n",
    "                              'batch-size': 32,\n",
    "                              'learning-rate': 0.001}\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_estimator.fit({'training': training_input_path, 'validation': validation_input_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK #7: DEPLOY THE MODEL WITHOUT ACCELERATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploying the model\n",
    "\n",
    "import time\n",
    "\n",
    "tf_endpoint_name = 'trafficsignclassifier-' + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "tf_predictor = tf_estimator.deploy(initial_instance_count = 1,\n",
    "                         instance_type = 'ml.t2.medium',  \n",
    "                         endpoint_name = tf_endpoint_name)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions from the end point\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Pre-processing the images\n",
    "\n",
    "num_samples = 5\n",
    "indices = random.sample(range(X_test.shape[0] - 1), num_samples)\n",
    "images = X_test[indices]/255\n",
    "labels = y_test[indices]\n",
    "\n",
    "for i in range(num_samples):\n",
    "    plt.subplot(1,num_samples,i+1)\n",
    "    plt.imshow(images[i])\n",
    "    plt.title(labels[i])\n",
    "    plt.axis('off')\n",
    "\n",
    "# Making predictions \n",
    "\n",
    "prediction = tf_predictor.predict(images.reshape(num_samples, 32, 32, 3))['predictions']\n",
    "prediction = np.array(prediction)\n",
    "predicted_label = prediction.argmax(axis=1)\n",
    "print('Predicted labels are: {}'.format(predicted_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting the end-point\n",
    "tf_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MINI CHALLENGE (TAKE HOME)\n",
    " - Try to improve the model accuracy by experimenting with Dropout, adding more convolutional layers, and changing the size of the filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXCELLENT JOB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MINI CHALLENGE SOLUTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Select a random number\n",
    "    index = np.random.randint(0, n_training)\n",
    "    # read and display an image with the selected index    \n",
    "    axes[i].imshow( X_test[index])\n",
    "    axes[i].set_title(y_test[index], fontsize = 15)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.subplots_adjust(hspace=0.4)\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
