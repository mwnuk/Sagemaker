{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M27qF7CTrBqc"
   },
   "source": [
    "# TASK #1: UNDERSTAND THE PROBLEM STATEMENT "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xNl52nl3qiyL"
   },
   "source": [
    "\n",
    "- Aim of the problem is to find the health insurance cost incured by Individuals based on thier age, gender, BMI, number of children, smoking habit and geo-location.\n",
    "\n",
    "- Features available are:\n",
    "\n",
    "    - sex: insurance contractor gender, female, male\n",
    "\n",
    "    - bmi: Body mass index (ideally 18.5 to 24.9)\n",
    "\n",
    "    - children: Number of children covered by health insurance / Number of dependents\n",
    "\n",
    "    - smoker: smoking habits\n",
    "\n",
    "    - region: the beneficiary's residential area in the US, northeast, southeast, southwest, northwest.\n",
    "\n",
    "    - charges: Individual medical costs billed by health insurance\n",
    "\n",
    "\n",
    "Data Source:https://www.kaggle.com/mirichoi0218/insurance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zKmFmyaGunc7"
   },
   "source": [
    "# TASK #2: IMPORT LIBRARIES AND DATASETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TYPES OF AVAILABLE SAGEMAKER IMAGES \n",
    "- Data Science [datascience-1.0]: Data Science is a Conda image with the most commonly used Python packages and libraries, such as NumPy and SciKit Learn.\n",
    "- Base Python [python-3.6]\n",
    "- MXNet (optimized for CPU) [mxnet-1.6-cpu-py36]\n",
    "- MXNet (optimized for GPU) [mxnet-1.6-gpu-py36]\n",
    "- PyTorch (optimized for CPU) [pytorch-1.4-cpu-py36]\n",
    "- PyTorch (optimized for GPU) [pytorch-1.4-gpu-py36]\n",
    "- TensorFlow (optimized for CPU) [tensorflow-1.15-cpu-py36]\n",
    "- TensorFlow (optimized for GPU) [tensorflow-1.15-gpu-py36]\n",
    "- TensorFlow 2 (optimized for CPU) [tensorflow-2.1-cpu-py36]\n",
    "- TensorFlow 2 (optimized for GPU) [tensorflow-2.1-gpu-py36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "S0Cx3743urFY",
    "outputId": "b820039b-7ccb-4a68-8206-77bae97680dc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MINI CHALLENGE\n",
    "- Read the CSV file \"insurance.csv\" using pandas \n",
    "- Visualize the first and last 5 rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tjIiJdM4u1IE"
   },
   "outputs": [],
   "source": [
    "# read the csv file \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "q4_wPDKCu5Uc",
    "outputId": "886d2aaf-0205-4f46-96a7-629d0f367d2f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tMcr7xqMQre2"
   },
   "source": [
    "# TASK #3: PERFORM EXPLORATORY DATA ANALYSIS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are any Null values\n",
    "sns.heatmap(insurance_df.isnull(), yticklabels = False, cbar = False, cmap=\"Blues\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "6JYkJo9pYaet",
    "outputId": "fcc89a98-b0a9-499d-acde-e480e78dccfc"
   },
   "outputs": [],
   "source": [
    "# check if there are any Null values\n",
    "insurance_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "hMq3-KWOx0e1",
    "outputId": "22a5b184-1f07-46ef-dfc1-f8377fd7042f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check the dataframe info\n",
    "\n",
    "insurance_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by region to see any relationship between region and charges\n",
    "# Seems like south east region has the highest charges and body mass index\n",
    "df_region = insurance_df.groupby(by='region').mean()\n",
    "df_region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MINI CHALLENGE\n",
    "- Group data by 'age' and examine the relationship between 'age' and 'charges'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique values in the 'sex' column\n",
    "insurance_df['sex'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert categorical variable to numerical\n",
    "\n",
    "insurance_df['sex'] = insurance_df['sex'].apply(lambda x: 0 if x == 'female' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the unique values in the 'smoker' column\n",
    "insurance_df['smoker'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical variable to numerical \n",
    "\n",
    "insurance_df['smoker'] = insurance_df['smoker'].apply(lambda x: 0 if x == 'no' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique values in 'region' column\n",
    "insurance_df['region'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_dummies = pd.get_dummies(insurance_df['region'], drop_first = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_df = pd.concat([insurance_df, region_dummies], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's drop the original 'region' column \n",
    "insurance_df.drop(['region'], axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MINI CHALLENGE\n",
    "- Calculate the mean and standard deviation of the age, charges and bmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "Nn1Oxk2SzPX3",
    "outputId": "95f0265a-5e75-4a32-d771-4b3d15850c3c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y0GmpAjG3GiH"
   },
   "source": [
    "# TASK #4: VISUALIZE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_df[['age', 'sex', 'bmi', 'children', 'smoker', 'charges']].hist(bins = 30, figsize = (20,20), color = 'r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Ka9uFRXSkWHw",
    "outputId": "f42a681e-93d4-4b1f-a29c-f58fc8a6f974"
   },
   "outputs": [],
   "source": [
    "# plot pairplot\n",
    "\n",
    "sns.pairplot(insurance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "1OiGun0tvU7W",
    "outputId": "22204cf6-1a4d-46c7-af61-a27511873584"
   },
   "outputs": [],
   "source": [
    "sns.regplot(x = 'age', y = 'charges', data = insurance_df)\n",
    "plt.show()\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MINI CHALLENGE\n",
    "- Obtain the regplot between bmi and charges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MINI CHALLENGE\n",
    " - Calculate and plot the correlation matrix\n",
    " - Which feature has the most positive correlation with charges?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "9q-tFxvskWDa",
    "outputId": "8834e9ec-7676-4e86-c5e7-20f4e9eccbcb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 932
    },
    "colab_type": "code",
    "id": "clmblKfur8rm",
    "outputId": "760b0882-8993-4aed-9c38-866ef8a7c6cd"
   },
   "outputs": [],
   "source": [
    "\n",
    "# smoker and age have positive correlations with charges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "53qDZFRn3-S1"
   },
   "source": [
    "# TASK #5: CREATE TRAINING AND TESTING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "8QQTkOBL1yUR",
    "outputId": "e79771c7-a34d-430f-db8a-fa4c1253af78"
   },
   "outputs": [],
   "source": [
    "insurance_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4OXZB2F21e4H"
   },
   "outputs": [],
   "source": [
    "X = insurance_df.drop(columns =['charges'])\n",
    "y = insurance_df['charges']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XpGU63Ne1e9P",
    "outputId": "e16c74ca-dc1c-416c-dc44-7f927bb99bc6"
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OjGj0RALA0qZ",
    "outputId": "26559a6c-880b-45b4-a1e8-3c4b92bea889"
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jIeiK1maA6mm"
   },
   "outputs": [],
   "source": [
    "X = np.array(X).astype('float32')\n",
    "y = np.array(y).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only take the numerical variables and scale them\n",
    "X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m6V7goNiA6xG"
   },
   "outputs": [],
   "source": [
    "#scaling the data before feeding the model\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "scaler_x = StandardScaler()\n",
    "X = scaler_x.fit_transform(X)\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y = scaler_y.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MINI CHALLENGE\n",
    "- Split the data into 20% Testing and 80% Training\n",
    "- Double check that the split was successful by getting the shape of both the training and testing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "idWHLv5alF4C"
   },
   "source": [
    "# TASK #6: TRAIN AND TEST A LINEAR REGRESSION MODEL IN SK-LEARN (NOTE THAT SAGEMAKER BUILT-IN ALGORITHMS ARE NOT USED HERE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yHL-6mKwBURs",
    "outputId": "10d71b6d-9c2b-4bab-8b27-d3c5883e6a25"
   },
   "outputs": [],
   "source": [
    "# using linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "regresssion_model_sklearn = LinearRegression()\n",
    "regresssion_model_sklearn.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "elD8m5N0BgEY",
    "outputId": "16a1813d-a0f1-4d1f-dc02-d7ad5a445417"
   },
   "outputs": [],
   "source": [
    "regresssion_model_sklearn_accuracy = regresssion_model_sklearn.score(X_test, y_test)\n",
    "regresssion_model_sklearn_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = regresssion_model_sklearn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_orig = scaler_y.inverse_transform(y_predict)\n",
    "y_test_orig = scaler_y.inverse_transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "RMSE = float(format(np.sqrt(mean_squared_error(y_test_orig, y_predict_orig)),'.3f'))\n",
    "MSE = mean_squared_error(y_test_orig, y_predict_orig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MINI CHALLENGE\n",
    "- calculate the mean absolute error, R2 and adjusted R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RMSE =',RMSE, '\\nMSE =',MSE, '\\nMAE =',MAE, '\\nR2 =', r2, '\\nAdjusted R2 =', adj_r2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK #7: TRAIN A LINEAR LEARNER MODEL USING SAGEMAKER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boto3 is the Amazon Web Services (AWS) Software Development Kit (SDK) for Python\n",
    "# Boto3 allows Python developer to write software that makes use of services like Amazon S3 and Amazon EC2\n",
    "\n",
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "# Let's create a Sagemaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Let's define the S3 bucket and prefix that we want to use in this session\n",
    "bucket = 'sagemaker-practical' # bucket named 'sagemaker-practical' was created beforehand\n",
    "prefix = 'linear_learner' # prefix is the subfolder within the bucket.\n",
    "\n",
    "# Let's get the execution role for the notebook instance. \n",
    "# This is the IAM role that you created when you created your notebook instance. You pass the role to the training job.\n",
    "# Note that AWS Identity and Access Management (IAM) role that Amazon SageMaker can assume to perform tasks on your behalf (for example, reading training results, called model artifacts, from the S3 bucket and writing training results to Amazon S3). \n",
    "role = sagemaker.get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = y_train[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io # The io module allows for dealing with various types of I/O (text I/O, binary I/O and raw I/O). \n",
    "import numpy as np\n",
    "import sagemaker.amazon.common as smac # sagemaker common libary\n",
    "\n",
    "# Code below converts the data in numpy array format to RecordIO format\n",
    "# This is the format required by Sagemaker Linear Learner \n",
    "\n",
    "buf = io.BytesIO() # create an in-memory byte array (buf is a buffer I will be writing to)\n",
    "smac.write_numpy_to_dense_tensor(buf, X_train, y_train)\n",
    "buf.seek(0) \n",
    "# When you write to in-memory byte arrays, it increments 1 every time you write to it\n",
    "# Let's reset that back to zero \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Code to upload RecordIO data to S3\n",
    " \n",
    "# Key refers to the name of the file    \n",
    "key = 'linear-train-data'\n",
    "\n",
    "# The following code uploads the data in record-io format to S3 bucket to be accessed later for training\n",
    "boto3.resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train', key)).upload_fileobj(buf)\n",
    "\n",
    "# Let's print out the training data location in s3\n",
    "s3_train_data = 's3://{}/{}/train/{}'.format(bucket, prefix, key)\n",
    "print('uploaded training data location: {}'.format(s3_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an output placeholder in S3 bucket to store the linear learner output\n",
    "\n",
    "output_location = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "print('Training artifacts will be uploaded to: {}'.format(output_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is used to get the training container of sagemaker built-in algorithms\n",
    "# all we have to do is to specify the name of the algorithm, that we want to use\n",
    "\n",
    "# Let's obtain a reference to the linearLearner container image\n",
    "# Note that all regression models are named estimators\n",
    "# You don't have to specify (hardcode) the region, get_image_uri will get the current region name using boto3.Session\n",
    "\n",
    "\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "container = get_image_uri(boto3.Session().region_name, 'linear-learner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have pass in the container, the type of instance that we would like to use for training \n",
    "# output path and sagemaker session into the Estimator. \n",
    "# We can also specify how many instances we would like to use for training\n",
    "\n",
    "linear = sagemaker.estimator.Estimator(container,\n",
    "                                       role, \n",
    "                                       train_instance_count = 1, \n",
    "                                       train_instance_type = 'ml.c4.xlarge',\n",
    "                                       output_path = output_location,\n",
    "                                       sagemaker_session = sagemaker_session)\n",
    "\n",
    "\n",
    "# We can tune parameters like the number of features that we are passing in, type of predictor like 'regressor' or 'classifier', mini batch size, epochs\n",
    "# Train 32 different versions of the model and will get the best out of them (built-in parameters optimization!)\n",
    "\n",
    "linear.set_hyperparameters(feature_dim = 8,\n",
    "                           predictor_type = 'regressor',\n",
    "                           mini_batch_size = 100,\n",
    "                           epochs = 100,\n",
    "                           num_models = 32,\n",
    "                           loss = 'absolute_loss')\n",
    "\n",
    "# Now we are ready to pass in the training data from S3 to train the linear learner model\n",
    "\n",
    "linear.fit({'train': s3_train_data})\n",
    "\n",
    "# Let's see the progress using cloudwatch logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MINI CHALLENGE\n",
    " - retrain the linear learner model using more epochs, more number of models. \n",
    " - Experiment with a different loss function and report any improvement or degradation in results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK #8: DEPLOY AND TEST THE TRAINED LINEAR LEARNER MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploying the model to perform inference \n",
    "\n",
    "linear_regressor = linear.deploy(initial_instance_count = 1,\n",
    "                                          instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import csv_serializer, json_deserializer\n",
    "\n",
    "# Content type overrides the data that will be passed to the deployed model, since the deployed model expects data in text/csv format.\n",
    "\n",
    "# Serializer accepts a single argument, the input data, and returns a sequence of bytes in the specified content type\n",
    "\n",
    "# Deserializer accepts two arguments, the result data and the response content type, and return a sequence of bytes in the specified content type.\n",
    "\n",
    "# Reference: https://sagemaker.readthedocs.io/en/stable/predictors.html\n",
    "\n",
    "linear_regressor.content_type = 'text/csv'\n",
    "linear_regressor.serializer = csv_serializer\n",
    "linear_regressor.deserializer = json_deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making prediction on the test data\n",
    "\n",
    "result = linear_regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result # results are in Json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the result is in json format, we access the scores by iterating through the scores in the predictions\n",
    "\n",
    "predictions = np.array([r['score'] for r in result['predictions']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_orig = scaler_y.inverse_transform(predictions)\n",
    "y_test_orig = scaler_y.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "RMSE = float(format(np.sqrt(mean_squared_error(y_test_orig, y_predict_orig)),'.3f'))\n",
    "MSE = mean_squared_error(y_test_orig, y_predict_orig)\n",
    "MAE = mean_absolute_error(y_test_orig, y_predict_orig)\n",
    "r2 = r2_score(y_test_orig, y_predict_orig)\n",
    "adj_r2 = 1-(1-r2)*(n-1)/(n-k-1)\n",
    "\n",
    "print('RMSE =',RMSE, '\\nMSE =',MSE, '\\nMAE =',MAE, '\\nR2 =', r2, '\\nAdjusted R2 =', adj_r2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the end-point\n",
    "\n",
    "linear_regressor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK #9: LET'S TRY A MORE COMPLEX ARTIFICIAL NEURAL NETWORK-BASED REGRESSION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = Adam()\n",
    "ANN_model = keras.Sequential()\n",
    "ANN_model.add(Dense(50, input_dim = 8))\n",
    "ANN_model.add(Activation('relu'))\n",
    "ANN_model.add(Dense(150))\n",
    "ANN_model.add(Activation('relu'))\n",
    "ANN_model.add(Dropout(0.5))\n",
    "ANN_model.add(Dense(150))\n",
    "ANN_model.add(Activation('relu'))\n",
    "ANN_model.add(Dropout(0.5))\n",
    "ANN_model.add(Dense(50))\n",
    "ANN_model.add(Activation('linear'))\n",
    "ANN_model.add(Dense(1))\n",
    "ANN_model.compile(loss = 'mse', optimizer = 'adam')\n",
    "ANN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN_model.compile(optimizer='Adam', loss='mean_squared_error')\n",
    "\n",
    "epochs_hist = ANN_model.fit(X_train, y_train, epochs = 100, batch_size = 20, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ANN_model.evaluate(X_test, y_test)\n",
    "accuracy_ANN = 1 - result\n",
    "print(\"Accuracy : {}\".format(accuracy_ANN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_hist.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs_hist.history['loss'])\n",
    "plt.plot(epochs_hist.history['val_loss'])\n",
    "plt.title('Model Loss Progress During Training')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training and Validation Loss')\n",
    "plt.legend(['Training Loss', 'Validation Loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = ANN_model.predict(X_test)\n",
    "plt.plot(y_test, y_predict, \"^\", color = 'r')\n",
    "plt.xlabel('Model Predictions')\n",
    "plt.ylabel('True Values')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_orig = scaler_y.inverse_transform(y_predict)\n",
    "y_test_orig = scaler_y.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test_orig, y_predict_orig, \"^\", color = 'r')\n",
    "plt.xlabel('Model Predictions')\n",
    "plt.ylabel('True Values')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "n\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "RMSE = float(format(np.sqrt(mean_squared_error(y_test_orig, y_predict_orig)),'.3f'))\n",
    "MSE = mean_squared_error(y_test_orig, y_predict_orig)\n",
    "MAE = mean_absolute_error(y_test_orig, y_predict_orig)\n",
    "r2 = r2_score(y_test_orig, y_predict_orig)\n",
    "adj_r2 = 1-(1-r2)*(n-1)/(n-k-1)\n",
    "\n",
    "print('RMSE =',RMSE, '\\nMSE =',MSE, '\\nMAE =',MAE, '\\nR2 =', r2, '\\nAdjusted R2 =', adj_r2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MINI CHALLENGE\n",
    "- Experiment with a deeper network with more neurons in the hidden layer\n",
    "- Experiment with no regularization (dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXCELLENT JOB!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Graduate_Admission_Prediction.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
